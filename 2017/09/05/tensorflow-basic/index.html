<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="ansvver's tech blog"><title>tensorflow基础概念 | ansvverのd機關</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">tensorflow基础概念</h1><a id="logo" href="/.">ansvverのd機關</a><p class="description">思考 記錄 重溫 理解</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">tensorflow基础概念</h1><div class="post-meta">Sep 5, 2017<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="clear"><div class="toc-article" id="toc"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#tensor"><span class="toc-number">1.</span> <span class="toc-text">tensor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TensorFlow"><span class="toc-number">2.</span> <span class="toc-text">TensorFlow</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ML-with-TF"><span class="toc-number">3.</span> <span class="toc-text">ML with TF</span></a></li></ol></div></div><div class="post-content"><p>笔记整理自：<a href="https://tensorflow.google.cn/get_started/get_started" target="_blank" rel="noopener">https://tensorflow.google.cn/get_started/get_started</a></p>
<p>TenserFlow version: 1.3</p>
<h3 id="tensor"><a href="#tensor" class="headerlink" title="tensor"></a>tensor</h3><p><code>tensor</code>是TensorFlow中最重要的数据单元，一个 tensor包含了原始值的一个集合，这些原始值是任意维的一个数组（ 原文：A tensor consists of a set of primitive values shaped into an array of any number of dimensions），那么一个tensor的<strong>rank</strong>就是其维度的数量，如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">3</span> <span class="comment"># a rank 0 tensor; this is a scalar with shape []</span></span><br><span class="line">[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>] <span class="comment"># a rank 1 tensor; this is a vector with shape [3]</span></span><br><span class="line">[[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>], [<span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>]] <span class="comment"># a rank 2 tensor; a matrix with shape [2, 3]</span></span><br><span class="line">[[[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>]], [[<span class="number">7.</span>, <span class="number">8.</span>, <span class="number">9.</span>]]] <span class="comment"># a rank 3 tensor with shape [2, 1, 3]</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h3><p>可以理解为TensorFlow最核心的程序由两个独立的步骤构成：</p>
<ol>
<li>构建计算图模型</li>
<li>运行计算图模型 </li>
</ol>
<p>在TensorFlow中，计算图模型由一系列节点通过TensorFlow操作组成。</p>
<p><code>constant</code>是节点的一种类型，它没有输出，输出是其内部存储的值，如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">node1 = tf.constant(<span class="number">3.0</span>, dtype=tf.float32)</span><br><span class="line">node2 = tf.constant(<span class="number">4.0</span>) <span class="comment"># also tf.float32 implicitly</span></span><br><span class="line">print(node1, node2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># Tensor("Const:0", shape=(), dtype=float32) Tensor("Const_1:0", shape=(), dtype=float32)</span></span><br></pre></td></tr></table></figure>
<p>上面只是构建了这些节点，想真正地得到结果，需要在一个<code>session</code>中执行这些节点，一个<code>session</code>包含了控制和TensorFlow运行时的状态，它其实是与后端C++处理的一个连接。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run([node1, node2]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># [3.0, 4.0]</span></span><br></pre></td></tr></table></figure>
<p>通过操作，可以将<code>Tensor</code>组合关联起来（Operations也是节点），如下构建一个新的图：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">node3 = tf.add(node1, node2)</span><br><span class="line">print(<span class="string">"node3:"</span>, node3)</span><br><span class="line">print(<span class="string">"sess.run(node3):"</span>, sess.run(node3))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># node3: Tensor("Add:0", shape=(), dtype=float32)</span></span><br><span class="line"><span class="comment"># sess.run(node3): 7.0</span></span><br></pre></td></tr></table></figure>
<p><code>TensorBoard</code>可以可视化地显示计算图模型</p>
<p><img src="http://yabuhoo.qiniudn.com/static/img/201709/tensor1.png" alt=""></p>
<p><code>placeholder</code>可以表示一个外部的输入，这个输入保证在后面会产生一个值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = tf.placeholder(tf.float32)</span><br><span class="line">b = tf.placeholder(tf.float32)</span><br><span class="line">adder_node = a + b <span class="comment"># + provides a shortcut for tf.add(a, b)</span></span><br></pre></td></tr></table></figure>
<p>以上三行代码有点想<code>lambda</code>这种匿名函数的语法方式，它接受<code>a</code>,<code>b</code>两个参数，以及一个计算符号。</p>
<p>我们可以字典参数的形式对<code>placeholder</code>赋真正的值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">print(sess.run(adder_node, &#123;a: 3, b: 4.5&#125;))</span><br><span class="line">print(sess.run(adder_node, &#123;a: [1, 3], b: [2, 4]&#125;))</span><br><span class="line"></span><br><span class="line"># Output:</span><br><span class="line"># 7.5</span><br><span class="line"># [ 3. 7.]</span><br></pre></td></tr></table></figure>
<p><img src="http://yabuhoo.qiniudn.com/static/img/201709/tensor2.png" alt=""></p>
<p>更复杂一些的，如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">add_and_triple = adder_node * <span class="number">3.</span></span><br><span class="line">print(sess.run(add_and_triple, &#123;a: <span class="number">3</span>, b: <span class="number">4.5</span>&#125;))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># 22.5</span></span><br></pre></td></tr></table></figure>
<p><img src="http://yabuhoo.qiniudn.com/static/img/201709/tensor3.png" alt=""></p>
<p>在机器学习中，我们常常需要训练参数，<code>Variable</code>使得我们能对图模型添加可训练的参数，常常由类型和值组成，如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">W = tf.Variable([<span class="number">.3</span>], dtype=tf.float32)</span><br><span class="line">b = tf.Variable([<span class="number">-.3</span>], dtype=tf.float32)</span><br><span class="line">x = tf.placeholder(tf.float32)</span><br><span class="line">linear_model = W * x + b</span><br></pre></td></tr></table></figure>
<p>常量会在调用<code>tf.constant</code>时初始化，但变量不会在调用<code>tf.Variable</code>时初始化，要初始化所有变量，可通过：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line">print(sess.run(linear_model, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]&#125;))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># [ 0. 0.30000001 0.60000002 0.90000004]</span></span><br></pre></td></tr></table></figure>
<p>一个简单地以误差的平方和为loss的计算方法如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y = tf.placeholder(tf.float32)</span><br><span class="line">squared_deltas = tf.square(linear_model - y)</span><br><span class="line">loss = tf.reduce_sum(squared_deltas)</span><br><span class="line">print(sess.run(loss, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], y: [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]&#125;))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># 23.66</span></span><br></pre></td></tr></table></figure>
<p>通过<code>tf.assign</code>可以对变量赋值：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">fixW = tf.assign(W, [<span class="number">-1.</span>])</span><br><span class="line">fixb = tf.assign(b, [<span class="number">1.</span>])</span><br><span class="line">sess.run([fixW, fixb])</span><br><span class="line">print(sess.run(loss, &#123;x: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], y: [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]&#125;))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line"><span class="comment"># 0.0</span></span><br></pre></td></tr></table></figure>
<h3 id="ML-with-TF"><a href="#ML-with-TF" class="headerlink" title="ML with TF"></a>ML with TF</h3><p>一个简单、完整的线性回归模型代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model parameters</span></span><br><span class="line">W = tf.Variable([<span class="number">.3</span>], dtype=tf.float32)</span><br><span class="line">b = tf.Variable([<span class="number">-.3</span>], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Model input and output</span></span><br><span class="line">x = tf.placeholder(tf.float32)</span><br><span class="line">linear_model = W * x + b</span><br><span class="line">y = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss</span></span><br><span class="line">loss = tf.reduce_sum(tf.square(linear_model - y)) <span class="comment"># sum of the squares</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># optimizer</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training data</span></span><br><span class="line">x_train = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">y_train = [<span class="number">0</span>, <span class="number">-1</span>, <span class="number">-2</span>, <span class="number">-3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># training loop</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init) <span class="comment"># reset values to wrong</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">  sess.run(train, &#123;x: x_train, y: y_train&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># evaluate training accuracy</span></span><br><span class="line">curr_W, curr_b, curr_loss = sess.run([W, b, loss], &#123;x: x_train, y: y_train&#125;)</span><br><span class="line">print(<span class="string">"W: %s b: %s loss: %s"</span>%(curr_W, curr_b, curr_loss))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11</span></span><br></pre></td></tr></table></figure>
<p>其中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># optimizer</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br></pre></td></tr></table></figure>
<p><code>tf.train</code>是TensorFlow提供的优化函数。</p>
<p>另外，<code>tf.estimator</code>包含了更高级的经典机器学习函数，以上线性回归的代码可改为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># NumPy is often used to load, manipulate and preprocess data.</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Declare list of features. We only have one numeric feature. There are many</span></span><br><span class="line"><span class="comment"># other types of columns that are more complicated and useful.</span></span><br><span class="line">feature_columns = [tf.feature_column.numeric_column(<span class="string">"x"</span>, shape=[<span class="number">1</span>])]</span><br><span class="line"></span><br><span class="line"><span class="comment"># An estimator is the front end to invoke training (fitting) and evaluation</span></span><br><span class="line"><span class="comment"># (inference). There are many predefined types like linear regression,</span></span><br><span class="line"><span class="comment"># linear classification, and many neural network classifiers and regressors.</span></span><br><span class="line"><span class="comment"># The following code provides an estimator that does linear regression.</span></span><br><span class="line">estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TensorFlow provides many helper methods to read and set up data sets.</span></span><br><span class="line"><span class="comment"># Here we use two data sets: one for training and one for evaluation</span></span><br><span class="line"><span class="comment"># We have to tell the function how many batches</span></span><br><span class="line"><span class="comment"># of data (num_epochs) we want and how big each batch should be.</span></span><br><span class="line">x_train = np.array([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</span><br><span class="line">y_train = np.array([<span class="number">0.</span>, <span class="number">-1.</span>, <span class="number">-2.</span>, <span class="number">-3.</span>])</span><br><span class="line">x_eval = np.array([<span class="number">2.</span>, <span class="number">5.</span>, <span class="number">8.</span>, <span class="number">1.</span>])</span><br><span class="line">y_eval = np.array([<span class="number">-1.01</span>, <span class="number">-4.1</span>, <span class="number">-7</span>, <span class="number">0.</span>])</span><br><span class="line">input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="keyword">None</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line">train_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line">eval_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_eval&#125;, y_eval, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># We can invoke 1000 training steps by invoking the method and passing the</span></span><br><span class="line"><span class="comment"># training data set.</span></span><br><span class="line">estimator.train(input_fn=input_fn, steps=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Here we evaluate how well our model did.</span></span><br><span class="line">train_metrics = estimator.evaluate(input_fn=train_input_fn)</span><br><span class="line">eval_metrics = estimator.evaluate(input_fn=eval_input_fn)</span><br><span class="line">print(<span class="string">"train metrics: %r"</span>% train_metrics)</span><br><span class="line">print(<span class="string">"eval metrics: %r"</span>% eval_metrics)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># train metrics: &#123;'loss': 1.2712867e-09, 'global_step': 1000&#125;</span></span><br><span class="line"><span class="comment"># eval metrics: &#123;'loss': 0.0025279333, 'global_step': 1000&#125;</span></span><br></pre></td></tr></table></figure>
<p>如果不想用预先定义好的模型，想自己实现内部的细节，可以使用<code>tf.estimator.Estimator</code>，实现内部的<code>model_fn</code>即可，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Declare list of features, we only have one real-valued feature</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span><span class="params">(features, labels, mode)</span>:</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Build a linear model and predict values</span></span><br><span class="line">  W = tf.get_variable(<span class="string">"W"</span>, [<span class="number">1</span>], dtype=tf.float64)</span><br><span class="line">  b = tf.get_variable(<span class="string">"b"</span>, [<span class="number">1</span>], dtype=tf.float64)</span><br><span class="line">  y = W * features[<span class="string">'x'</span>] + b</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Loss sub-graph</span></span><br><span class="line">  loss = tf.reduce_sum(tf.square(y - labels))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Training sub-graph</span></span><br><span class="line">  global_step = tf.train.get_global_step()</span><br><span class="line">  optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>)</span><br><span class="line">  train = tf.group(optimizer.minimize(loss),</span><br><span class="line">                   tf.assign_add(global_step, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">  <span class="comment"># EstimatorSpec connects subgraphs we built to the</span></span><br><span class="line">  <span class="comment"># appropriate functionality.</span></span><br><span class="line">  <span class="keyword">return</span> tf.estimator.EstimatorSpec(</span><br><span class="line">      mode=mode,</span><br><span class="line">      predictions=y,</span><br><span class="line">      loss=loss,</span><br><span class="line">      train_op=train)</span><br><span class="line"></span><br><span class="line">estimator = tf.estimator.Estimator(model_fn=model_fn)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define our data sets</span></span><br><span class="line">x_train = np.array([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>])</span><br><span class="line">y_train = np.array([<span class="number">0.</span>, <span class="number">-1.</span>, <span class="number">-2.</span>, <span class="number">-3.</span>])</span><br><span class="line">x_eval = np.array([<span class="number">2.</span>, <span class="number">5.</span>, <span class="number">8.</span>, <span class="number">1.</span>])</span><br><span class="line">y_eval = np.array([<span class="number">-1.01</span>, <span class="number">-4.1</span>, <span class="number">-7</span>, <span class="number">0.</span>])</span><br><span class="line">input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="keyword">None</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line">train_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_train&#125;, y_train, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line">eval_input_fn = tf.estimator.inputs.numpy_input_fn(</span><br><span class="line">    &#123;<span class="string">"x"</span>: x_eval&#125;, y_eval, batch_size=<span class="number">4</span>, num_epochs=<span class="number">1000</span>, shuffle=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># train</span></span><br><span class="line">estimator.train(input_fn=input_fn, steps=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Here we evaluate how well our model did.</span></span><br><span class="line">train_metrics = estimator.evaluate(input_fn=train_input_fn)</span><br><span class="line">eval_metrics = estimator.evaluate(input_fn=eval_input_fn)</span><br><span class="line">print(<span class="string">"train metrics: %r"</span>% train_metrics)</span><br><span class="line">print(<span class="string">"eval metrics: %r"</span>% eval_metrics)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Output:</span></span><br><span class="line"><span class="comment"># train metrics: &#123;'loss': 1.227995e-11, 'global_step': 1000&#125;</span></span><br><span class="line"><span class="comment"># eval metrics: &#123;'loss': 0.01010036, 'global_step': 1000&#125;</span></span><br></pre></td></tr></table></figure>
</div><div class="tags"><a href="/tags/Python/">Python</a><a href="/tags/TensorFlow/">TensorFlow</a></div><div class="post-nav"><a class="next" href="/2017/09/04/matplot_examples/">matplotlib示例</a></div><div id="container"></div><link rel="stylesheet" href="/css/default.css?v=0.0.0"><script src="/js/gitment.browser.js?v=0.0.0"></script><script>var gitment = new Gitment({
  owner: 'ansvver',
  repo: 'ansvver.github.io',
  oauth: {
    client_id: 'd83ac015fb516c998b72',
    client_secret: 'd18e99d572502728f4509ae4ddd16db173b39a3d',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/程序设计/">程序设计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/算法实践/">算法实践</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/MongoDB/" style="font-size: 15px;">MongoDB</a> <a href="/tags/递归/" style="font-size: 15px;">递归</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/09/05/tensorflow-basic/">tensorflow基础概念</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/04/matplot_examples/">matplotlib示例</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/28/pandas-code/">Pandas code</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/18/numpy-part3/">Numpy基本用法3</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/11/numpy-part2/">Numpy基本用法2</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/09/numpy-part1/">Numpy基本用法1</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/09/ipython-note/">IPython基本用法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/19/incremental-update-dict-in-pymongo/">增量更新MongoDB字典数据</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">ansvverのd機關.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = '//hm.baidu.com/hm.js?' + '1848a65ec59a9c0e6bf99f245cb5b204';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>